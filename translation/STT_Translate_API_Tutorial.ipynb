{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Speech-to-Text Translation API Using Saaras Tutorial**\n",
        "\n",
        "---\n",
        "\n",
        "This notebook provides a step-by-step guide on how to use the **STT-Translate API** for translating audio files into text using **Saaras**. It includes instructions for installation, setting up the API key, uploading audio files, and translating audio using the API.\n"
      ],
      "metadata": {
        "id": "oXjegG1sIj5k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **0. Installation**\n",
        "\n",
        "Before you begin, ensure you have the necessary Python libraries installed. Run the following commands to install the required packages:"
      ],
      "metadata": {
        "id": "ozox6beyIlO1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install requests pandas pydub\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zDMR887aJHRd",
        "outputId": "097ebc86-63f9-414a-82a8-56633b175368"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (0.25.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.12.14)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1. Import Required Libraries**\n",
        "\n",
        "This section imports the necessary Python libraries for making HTTP requests, handling audio files, and managing data."
      ],
      "metadata": {
        "id": "26ekmzdPdNv1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import io"
      ],
      "metadata": {
        "id": "aKIOxPGodKmD"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **requests**: For making HTTP requests to the API.\n",
        "- **pandas**: For data manipulation (optional, depending on your use case).\n"
      ],
      "metadata": {
        "id": "DLXY5ksvJO43"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2. Set Up the API Endpoint and Payload**\n",
        "\n",
        "To use the Saaras API, you need an API subscription key. Follow these steps to set up your API key:\n",
        "\n",
        "1. **Obtain your API key**: If you donâ€™t have an API key, sign up on the [Sarvam AI Dashboard](https://dashboard.sarvam.ai/) to get one.\n",
        "2. **Replace the placeholder key**: In the code below, replace \"YOUR_SARVAM_AI_API_KEY\" with your actual API key."
      ],
      "metadata": {
        "id": "49zcUJ2LJnr5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SARVAM_AI_API=\"YOUR_SARVAM_AI_API_KEY\""
      ],
      "metadata": {
        "id": "EKx_nfiuJNvY"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***2.1 Setting Up the API Endpoint and Payload***\n",
        "\n",
        "This section defines the API endpoint and the payload for the translation request. Replace the placeholder values with your actual API key and desired parameters.**bold text**"
      ],
      "metadata": {
        "id": "FnvYBB1hKo6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# API endpoint for speech-to-text translation\n",
        "api_url = \"https://api.sarvam.ai/speech-to-text-translate\"\n",
        "\n",
        "# Headers containing the API subscription key\n",
        "headers = {\n",
        "    \"api-subscription-key\": SARVAM_AI_API  # Replace with your API key\n",
        "}\n",
        "\n",
        "# Data payload for the translation request\n",
        "data = {\n",
        "    \"model\": \"saaras:v2\",  # Specify the model to be used\n",
        "    \"with_diarization\": False  # Set to True for speaker diarization\n",
        "}\n"
      ],
      "metadata": {
        "id": "80sifgpCKqo5"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3. Uploading Audio Files**\n",
        "\n",
        "To translate audio, you need to upload a `.wav` file. Follow these steps:\n",
        "\n",
        "1. **Prepare your audio file**: Ensure your audio file is in `.wav` format. If your file is in a different format, you can use tools like `pydub` to convert it.\n",
        "2. **Upload the file**: If you're using Google Colab, you can upload the file using the file uploader:"
      ],
      "metadata": {
        "id": "KlAvj8-eJvJW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "audio_file_path = list(uploaded.keys())[0]  # Get the name of the uploaded file"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "GVXgWLUCJmfN",
        "outputId": "1664f4a8-2757-46b2-a4f8-f56884774192"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-99a1b915-eedc-4f72-827b-1aa5a2efcdfa\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-99a1b915-eedc-4f72-827b-1aa5a2efcdfa\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving test.wav to test (3).wav\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you're working locally, ensure the file is in the same directory as your notebook and specify the file name:\n",
        "\n",
        "```audio_file_path = \"test.wav\"  Replace with your file name```"
      ],
      "metadata": {
        "id": "yNt4jE9VJ8PO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **4. Speech-to-Text Translation API**\n",
        "\n",
        "This section demonstrates how to use the *STT-Translate API* for translating audio files into text using *Saaras*. The API automatically identifies the language of the audio and supports long audio files by splitting them into chunks."
      ],
      "metadata": {
        "id": "ddBduSODKMh_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **4.1. Splitting Audio into Chunks**\n",
        "\n",
        "The `split_audio` function splits an audio file into smaller chunks of a specified duration. This is useful for processing long audio files that exceed the API's input length limit."
      ],
      "metadata": {
        "id": "JmczslC5Kf2h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pydub import AudioSegment\n",
        "\n",
        "def split_audio(audio_path, chunk_duration_ms):\n",
        "    \"\"\"\n",
        "    Splits an audio file into smaller chunks of specified duration.\n",
        "\n",
        "    Args:\n",
        "        audio_path (str): Path to the audio file to be split.\n",
        "        chunk_duration_ms (int): Duration of each chunk in milliseconds.\n",
        "\n",
        "    Returns:\n",
        "        list: A list of AudioSegment objects representing the audio chunks.\n",
        "    \"\"\"\n",
        "    audio = AudioSegment.from_file(audio_path)  # Load the audio file\n",
        "    chunks = []\n",
        "    if len(audio) > chunk_duration_ms:\n",
        "        # Split the audio into chunks of the specified duration\n",
        "        for i in range(0, len(audio), chunk_duration_ms):\n",
        "            chunks.append(audio[i:i + chunk_duration_ms])\n",
        "    else:\n",
        "        # If the audio is shorter than the chunk duration, use the entire audio\n",
        "        chunks.append(audio)\n",
        "    return chunks\n"
      ],
      "metadata": {
        "id": "xw55iT6WKhRj"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **4.2. Translating Audio**\n",
        "\n",
        "The `translate_audio` function translates audio chunks using the Saaras API. It handles the API request for each chunk and collates the results."
      ],
      "metadata": {
        "id": "V6Gb2tyuKkIY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def translate_audio(audio_file_path, api_url, headers, data, chunk_duration_ms=5*60*1000):\n",
        "    \"\"\"\n",
        "    Translates audio into text with optional diarization and timestamps.\n",
        "\n",
        "    Args:\n",
        "        audio_file_path (str): Path to the audio file.\n",
        "        api_url (str): API endpoint URL for Speech-to-Text and Translate.\n",
        "        headers (dict): Headers for API authentication.\n",
        "        data (dict): Payload containing model and other options like diarization.\n",
        "        chunk_duration_ms (int): Duration of each audio chunk in milliseconds.\n",
        "\n",
        "    Returns:\n",
        "        dict: Collated response containing the transcript and word-level timestamps.\n",
        "    \"\"\"\n",
        "    # Split the audio into chunks\n",
        "    chunks = split_audio(audio_file_path, chunk_duration_ms)\n",
        "    responses = []\n",
        "\n",
        "    # Process each chunk\n",
        "    for idx, chunk in enumerate(chunks):\n",
        "        # Export the chunk to a BytesIO object (in-memory binary stream)\n",
        "        chunk_buffer = io.BytesIO()\n",
        "        chunk.export(chunk_buffer, format=\"wav\")\n",
        "        chunk_buffer.seek(0)  # Reset the pointer to the start of the stream\n",
        "\n",
        "        # Prepare the file for the API request\n",
        "        files = {'file': ('audiofile.wav', chunk_buffer, 'audio/wav')}\n",
        "\n",
        "        try:\n",
        "            # Make the POST request to the API\n",
        "            response = requests.post(api_url, headers=headers, files=files, data=data)\n",
        "            if response.status_code == 200 or response.status_code == 201:\n",
        "                print(f\"Chunk {idx} POST Request Successful!\")\n",
        "                response_data = response.json()\n",
        "                transcript = response_data.get(\"transcript\", \"\")\n",
        "                responses.append({\"transcript\": transcript})\n",
        "            else:\n",
        "                # Handle failed requests\n",
        "                print(f\"Chunk {idx} POST Request failed with status code: {response.status_code}\")\n",
        "                print(\"Response:\", response.text)\n",
        "        except Exception as e:\n",
        "            # Handle any exceptions during the request\n",
        "            print(f\"Error processing chunk {idx}: {e}\")\n",
        "        finally:\n",
        "            # Ensure the buffer is closed after processing\n",
        "            chunk_buffer.close()\n",
        "\n",
        "    # Collate the transcriptions from all chunks\n",
        "    collated_transcript = \" \".join([resp[\"transcript\"] for resp in responses])\n",
        "    collated_response = {\n",
        "        \"transcript\": collated_transcript,\n",
        "        \"language\": response_data.get(\"language_code\")\n",
        "    }\n",
        "    return collated_response\n"
      ],
      "metadata": {
        "id": "pM9v3Zg2Kibx"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **4.3 Translating the Audio**\n",
        "\n",
        "This section calls the `translate_audio` function to translate the audio file. Replace `audio_file_path` with the path to your audio file."
      ],
      "metadata": {
        "id": "iblVRdZuKzBo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to the audio file to be translated\n",
        "# audio_file_path = \"test.wav\"  # Replace with your file path\n",
        "\n",
        "# Translate the audio\n",
        "translation = translate_audio(audio_file_path, api_url, headers, data)\n",
        "\n",
        "# Display the translation results\n",
        "translation\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zQ1Hdwo0K237",
        "outputId": "207cd10d-70f8-453f-d62c-6725da26baad"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chunk 0 POST Request Successful!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'transcript': \"There are many ethical stories in English that are beneficial for children. They activate your child's imagination, entertain them, and make them happy. Short ethical stories are ideal to keep them focused and focused throughout the story.\",\n",
              " 'language': 'hi-IN'}"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **5. Conclusion**\n",
        "\n",
        "This tutorial demonstrated how to use the **Saaras API** for translating audio files into text. By following the steps, you can easily translate audio, even long files, by splitting them into smaller chunks. The process involves installing required libraries, setting up your API key, uploading audio, and translating it using the provided functions.\n",
        "\n",
        "---\n",
        "\n",
        "## **6. Additional Resources**\n",
        "\n",
        "For more details, refer to the official **Saaras API documentation** and join the community for support:\n",
        "\n",
        "- **Documentation**: [docs.sarvam.ai](https://docs.sarvam.ai/)\n",
        "- **Community**: [Join the Discord Community](https://discord.gg/hTuVuPNF)\n",
        "\n",
        "---\n",
        "\n",
        "## **7. Final Notes**\n",
        "\n",
        "- Keep your API key secure.\n",
        "- Use clear audio for best results.\n",
        "- Explore advanced features like diarization and word-level timestamps.\n",
        "\n",
        "**Keep Building!** ðŸš€"
      ],
      "metadata": {
        "id": "IeHx5Y6jK6KT"
      }
    }
  ]
}